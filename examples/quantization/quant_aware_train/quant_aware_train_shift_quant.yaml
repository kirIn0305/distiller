quantizers:
  linear_quantizer:
    class: QuantAwareTrainShiftLinearQuantizer
    bits_activations: 8
    bits_weights: 8
    #mode: 'ASYMMETRIC_UNSIGNED'  # Can try "SYMMETRIC" as well
    mode: 'SYMMETRIC'  # Can try "SYMMETRIC" as well
    ema_decay: 0.999   # Decay value for exponential moving average tracking of activation ranges
    per_channel_wts: True

lr_schedulers:
  training_lr:
    class: MultiStepLR
    milestones: [60, 120]
    gammas: 0.1

policies:
    - quantizer:
        instance_name: linear_quantizer
      # For now putting a large range here, which should cover both training from scratch or resuming from some
      # pre-trained checkpoint at some unknown epoch
      starting_epoch: 0
      ending_epoch: 300
      frequency: 1

    - lr_scheduler:
        instance_name: training_lr
      starting_epoch: 0
      ending_epoch: 121
      frequency: 1
